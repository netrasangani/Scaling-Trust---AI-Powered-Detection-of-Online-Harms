# AI-Powered Sarcasm and Harmful Content Detection

## ðŸ“Œ Overview
In today's digital world, online conversations can contain sarcasm, harmful speech, and toxic content. Traditional moderation techniques struggle to identify these nuances, leading to potential misunderstandings and online harm.

This project utilizes **pretrained NLP models from Hugging Face** to detect **sarcasm and harmful content** in text-based conversations, helping to build safer online communities.

We have made a prototype of our project and the details are mentioned below:

## ðŸš€ Features
âœ… **Sarcasm Detection:** Identifies sarcastic messages using a fine-tuned BERT-based model.  
âœ… **Harmful Content Detection:** Detects toxic, offensive, and harmful speech using a specialized NLP model.  
âœ… **Machine Learning Powered:** Leverages state-of-the-art **transformer-based models** for high accuracy.  
âœ… **User-Friendly Interface:** A frontend UI for real-time text analysis.  
âœ… **Fast and Scalable:** Processes conversations efficiently for large-scale moderation.

## ðŸ”§ Technologies Used
- **Python** (Backend processing)
- **Transformers (Hugging Face)** for NLP models
- **TensorFlow / PyTorch** for Deep Learning
- **Frontend:** React.js / HTML-CSS-JS

## ðŸ“¦ Models Used
We used **pretrained models from Hugging Face**:
1. **Sarcasm Detection:** [`jkhan447/sarcasm-detection-Bert-base-uncased-newdata`](https://huggingface.co/jkhan447/sarcasm-detection-Bert-base-uncased-newdata)
2. **Harmful Content Detection:** [`unitary/toxic-bert`](https://huggingface.co/unitary/toxic-bert)

Our Frontend would look something like this after the project is completed:
![online_harms_UI](https://github.com/user-attachments/assets/eebd1fd6-734e-44f7-9f12-0fb7b7fa5c63)
